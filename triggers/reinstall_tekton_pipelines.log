namespace/tekton-pipelines configured
podsecuritypolicy.policy/tekton-pipelines configured
clusterrole.rbac.authorization.k8s.io/tekton-pipelines-controller-cluster-access unchanged
clusterrole.rbac.authorization.k8s.io/tekton-pipelines-controller-tenant-access unchanged
clusterrole.rbac.authorization.k8s.io/tekton-pipelines-webhook-cluster-access unchanged
role.rbac.authorization.k8s.io/tekton-pipelines-controller unchanged
role.rbac.authorization.k8s.io/tekton-pipelines-webhook unchanged
role.rbac.authorization.k8s.io/tekton-pipelines-leader-election unchanged
serviceaccount/tekton-pipelines-controller configured
serviceaccount/tekton-pipelines-webhook unchanged
clusterrolebinding.rbac.authorization.k8s.io/tekton-pipelines-controller-cluster-access unchanged
clusterrolebinding.rbac.authorization.k8s.io/tekton-pipelines-controller-tenant-access unchanged
clusterrolebinding.rbac.authorization.k8s.io/tekton-pipelines-webhook-cluster-access unchanged
rolebinding.rbac.authorization.k8s.io/tekton-pipelines-controller unchanged
rolebinding.rbac.authorization.k8s.io/tekton-pipelines-webhook unchanged
rolebinding.rbac.authorization.k8s.io/tekton-pipelines-controller-leaderelection unchanged
rolebinding.rbac.authorization.k8s.io/tekton-pipelines-webhook-leaderelection unchanged
customresourcedefinition.apiextensions.k8s.io/clustertasks.tekton.dev configured
customresourcedefinition.apiextensions.k8s.io/conditions.tekton.dev configured
customresourcedefinition.apiextensions.k8s.io/images.caching.internal.knative.dev configured
customresourcedefinition.apiextensions.k8s.io/pipelines.tekton.dev configured
customresourcedefinition.apiextensions.k8s.io/pipelineruns.tekton.dev configured
customresourcedefinition.apiextensions.k8s.io/pipelineresources.tekton.dev configured
customresourcedefinition.apiextensions.k8s.io/runs.tekton.dev configured
customresourcedefinition.apiextensions.k8s.io/tasks.tekton.dev configured
customresourcedefinition.apiextensions.k8s.io/taskruns.tekton.dev configured
secret/webhook-certs configured
validatingwebhookconfiguration.admissionregistration.k8s.io/validation.webhook.pipeline.tekton.dev configured
mutatingwebhookconfiguration.admissionregistration.k8s.io/webhook.pipeline.tekton.dev configured
validatingwebhookconfiguration.admissionregistration.k8s.io/config.webhook.pipeline.tekton.dev configured
clusterrole.rbac.authorization.k8s.io/tekton-aggregate-edit configured
clusterrole.rbac.authorization.k8s.io/tekton-aggregate-view configured
configmap/config-leader-election unchanged
configmap/config-registry-cert unchanged
deployment.apps/tekton-pipelines-controller unchanged
service/tekton-pipelines-controller configured
horizontalpodautoscaler.autoscaling/tekton-pipelines-webhook unchanged
poddisruptionbudget.policy/tekton-pipelines-webhook unchanged
deployment.apps/tekton-pipelines-webhook unchanged
service/tekton-pipelines-webhook configured
Error from server (InternalError): error when applying patch:
{"metadata":{"annotations":{"kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"v1\",\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"labels\":{\"app.kubernetes.io/instance\":\"default\",\"app.kubernetes.io/part-of\":\"tekton-pipelines\"},\"name\":\"config-artifact-bucket\",\"namespace\":\"tekton-pipelines\"}}\n"},"labels":{"app.kubernetes.io/instance":"default","app.kubernetes.io/part-of":"tekton-pipelines"}}}
to:
Resource: "/v1, Resource=configmaps", GroupVersionKind: "/v1, Kind=ConfigMap"
Name: "config-artifact-bucket", Namespace: "tekton-pipelines"
for: "tekton-pipelines-release.yaml": Internal error occurred: failed calling webhook "config.webhook.pipeline.tekton.dev": Post https://tekton-pipelines-webhook.tekton-pipelines.svc:443/config-validation?timeout=10s: no endpoints available for service "tekton-pipelines-webhook"
Error from server (InternalError): error when applying patch:
{"metadata":{"annotations":{"kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"v1\",\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"labels\":{\"app.kubernetes.io/instance\":\"default\",\"app.kubernetes.io/part-of\":\"tekton-pipelines\"},\"name\":\"config-artifact-pvc\",\"namespace\":\"tekton-pipelines\"}}\n"},"labels":{"app.kubernetes.io/instance":"default","app.kubernetes.io/part-of":"tekton-pipelines"}}}
to:
Resource: "/v1, Resource=configmaps", GroupVersionKind: "/v1, Kind=ConfigMap"
Name: "config-artifact-pvc", Namespace: "tekton-pipelines"
for: "tekton-pipelines-release.yaml": Internal error occurred: failed calling webhook "config.webhook.pipeline.tekton.dev": Post https://tekton-pipelines-webhook.tekton-pipelines.svc:443/config-validation?timeout=10s: no endpoints available for service "tekton-pipelines-webhook"
Error from server (InternalError): error when applying patch:
{"data":{"_example":"################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# default-timeout-minutes contains the default number of\n# minutes to use for TaskRun and PipelineRun, if none is specified.\ndefault-timeout-minutes: \"60\"  # 60 minutes\n\n# default-service-account contains the default service account name\n# to use for TaskRun and PipelineRun, if none is specified.\ndefault-service-account: \"default\"\n\n# default-managed-by-label-value contains the default value given to the\n# \"app.kubernetes.io/managed-by\" label applied to all Pods created for\n# TaskRuns. If a user's requested TaskRun specifies another value for this\n# label, the user's request supercedes.\ndefault-managed-by-label-value: \"tekton-pipelines\"\n\n# default-pod-template contains the default pod template to use\n# TaskRun and PipelineRun, if none is specified. If a pod template\n# is specified, the default pod template is ignored.\n# default-pod-template:\n\n# default-cloud-events-sink contains the default CloudEvents sink to be\n# used for TaskRun and PipelineRun, when no sink is specified.\n# Note that right now it is still not possible to set a PipelineRun or\n# TaskRun specific sink, so the default is the only option available.\n# If no sink is specified, no CloudEvent is generated\n# default-cloud-events-sink:\n\n# default-task-run-workspace-binding contains the default workspace\n# configuration provided for any Workspaces that a Task declares\n# but that a TaskRun does not explicitly provide.\n# default-task-run-workspace-binding: |\n#   emptyDir: {}\n"},"metadata":{"annotations":{"kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"v1\",\"data\":{\"_example\":\"################################\\n#                              #\\n#    EXAMPLE CONFIGURATION     #\\n#                              #\\n################################\\n\\n# This block is not actually functional configuration,\\n# but serves to illustrate the available configuration\\n# options and document them in a way that is accessible\\n# to users that `kubectl edit` this config map.\\n#\\n# These sample configuration options may be copied out of\\n# this example block and unindented to be in the data block\\n# to actually change the configuration.\\n\\n# default-timeout-minutes contains the default number of\\n# minutes to use for TaskRun and PipelineRun, if none is specified.\\ndefault-timeout-minutes: \\\"60\\\"  # 60 minutes\\n\\n# default-service-account contains the default service account name\\n# to use for TaskRun and PipelineRun, if none is specified.\\ndefault-service-account: \\\"default\\\"\\n\\n# default-managed-by-label-value contains the default value given to the\\n# \\\"app.kubernetes.io/managed-by\\\" label applied to all Pods created for\\n# TaskRuns. If a user's requested TaskRun specifies another value for this\\n# label, the user's request supercedes.\\ndefault-managed-by-label-value: \\\"tekton-pipelines\\\"\\n\\n# default-pod-template contains the default pod template to use\\n# TaskRun and PipelineRun, if none is specified. If a pod template\\n# is specified, the default pod template is ignored.\\n# default-pod-template:\\n\\n# default-cloud-events-sink contains the default CloudEvents sink to be\\n# used for TaskRun and PipelineRun, when no sink is specified.\\n# Note that right now it is still not possible to set a PipelineRun or\\n# TaskRun specific sink, so the default is the only option available.\\n# If no sink is specified, no CloudEvent is generated\\n# default-cloud-events-sink:\\n\\n# default-task-run-workspace-binding contains the default workspace\\n# configuration provided for any Workspaces that a Task declares\\n# but that a TaskRun does not explicitly provide.\\n# default-task-run-workspace-binding: |\\n#   emptyDir: {}\\n\"},\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"labels\":{\"app.kubernetes.io/instance\":\"default\",\"app.kubernetes.io/part-of\":\"tekton-pipelines\"},\"name\":\"config-defaults\",\"namespace\":\"tekton-pipelines\"}}\n"},"labels":{"app.kubernetes.io/instance":"default","app.kubernetes.io/part-of":"tekton-pipelines"}}}
to:
Resource: "/v1, Resource=configmaps", GroupVersionKind: "/v1, Kind=ConfigMap"
Name: "config-defaults", Namespace: "tekton-pipelines"
for: "tekton-pipelines-release.yaml": Internal error occurred: failed calling webhook "config.webhook.pipeline.tekton.dev": Post https://tekton-pipelines-webhook.tekton-pipelines.svc:443/config-validation?timeout=10s: no endpoints available for service "tekton-pipelines-webhook"
Error from server (InternalError): error when applying patch:
{"data":{"disable-affinity-assistant":"false","disable-creds-init":"false","enable-custom-tasks":"false","enable-tekton-oci-bundles":"false","require-git-ssh-secret-known-hosts":"false","running-in-environment-with-injected-sidecars":"true"},"metadata":{"annotations":{"kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"v1\",\"data\":{\"disable-affinity-assistant\":\"false\",\"disable-creds-init\":\"false\",\"disable-home-env-overwrite\":\"false\",\"disable-working-directory-overwrite\":\"false\",\"enable-custom-tasks\":\"false\",\"enable-tekton-oci-bundles\":\"false\",\"require-git-ssh-secret-known-hosts\":\"false\",\"running-in-environment-with-injected-sidecars\":\"true\"},\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"labels\":{\"app.kubernetes.io/instance\":\"default\",\"app.kubernetes.io/part-of\":\"tekton-pipelines\"},\"name\":\"feature-flags\",\"namespace\":\"tekton-pipelines\"}}\n"},"labels":{"app.kubernetes.io/instance":"default","app.kubernetes.io/part-of":"tekton-pipelines"}}}
to:
Resource: "/v1, Resource=configmaps", GroupVersionKind: "/v1, Kind=ConfigMap"
Name: "feature-flags", Namespace: "tekton-pipelines"
for: "tekton-pipelines-release.yaml": Internal error occurred: failed calling webhook "config.webhook.pipeline.tekton.dev": Post https://tekton-pipelines-webhook.tekton-pipelines.svc:443/config-validation?timeout=10s: no endpoints available for service "tekton-pipelines-webhook"
Error from server (InternalError): error when applying patch:
{"data":{"zap-logger-config":"{\n  \"level\": \"info\",\n  \"development\": false,\n  \"sampling\": {\n    \"initial\": 100,\n    \"thereafter\": 100\n  },\n  \"outputPaths\": [\"stdout\"],\n  \"errorOutputPaths\": [\"stderr\"],\n  \"encoding\": \"json\",\n  \"encoderConfig\": {\n    \"timeKey\": \"ts\",\n    \"levelKey\": \"level\",\n    \"nameKey\": \"logger\",\n    \"callerKey\": \"caller\",\n    \"messageKey\": \"msg\",\n    \"stacktraceKey\": \"stacktrace\",\n    \"lineEnding\": \"\",\n    \"levelEncoder\": \"\",\n    \"timeEncoder\": \"iso8601\",\n    \"durationEncoder\": \"\",\n    \"callerEncoder\": \"\"\n  }\n}\n"},"metadata":{"annotations":{"kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"v1\",\"data\":{\"loglevel.controller\":\"info\",\"loglevel.webhook\":\"info\",\"zap-logger-config\":\"{\\n  \\\"level\\\": \\\"info\\\",\\n  \\\"development\\\": false,\\n  \\\"sampling\\\": {\\n    \\\"initial\\\": 100,\\n    \\\"thereafter\\\": 100\\n  },\\n  \\\"outputPaths\\\": [\\\"stdout\\\"],\\n  \\\"errorOutputPaths\\\": [\\\"stderr\\\"],\\n  \\\"encoding\\\": \\\"json\\\",\\n  \\\"encoderConfig\\\": {\\n    \\\"timeKey\\\": \\\"ts\\\",\\n    \\\"levelKey\\\": \\\"level\\\",\\n    \\\"nameKey\\\": \\\"logger\\\",\\n    \\\"callerKey\\\": \\\"caller\\\",\\n    \\\"messageKey\\\": \\\"msg\\\",\\n    \\\"stacktraceKey\\\": \\\"stacktrace\\\",\\n    \\\"lineEnding\\\": \\\"\\\",\\n    \\\"levelEncoder\\\": \\\"\\\",\\n    \\\"timeEncoder\\\": \\\"iso8601\\\",\\n    \\\"durationEncoder\\\": \\\"\\\",\\n    \\\"callerEncoder\\\": \\\"\\\"\\n  }\\n}\\n\"},\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"labels\":{\"app.kubernetes.io/instance\":\"default\",\"app.kubernetes.io/part-of\":\"tekton-pipelines\"},\"name\":\"config-logging\",\"namespace\":\"tekton-pipelines\"}}\n"},"labels":{"app.kubernetes.io/instance":"default","app.kubernetes.io/part-of":"tekton-pipelines"}}}
to:
Resource: "/v1, Resource=configmaps", GroupVersionKind: "/v1, Kind=ConfigMap"
Name: "config-logging", Namespace: "tekton-pipelines"
for: "tekton-pipelines-release.yaml": Internal error occurred: failed calling webhook "config.webhook.pipeline.tekton.dev": Post https://tekton-pipelines-webhook.tekton-pipelines.svc:443/config-validation?timeout=10s: no endpoints available for service "tekton-pipelines-webhook"
Error from server (InternalError): error when applying patch:
{"metadata":{"annotations":{"kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"v1\",\"data\":{\"_example\":\"################################\\n#                              #\\n#    EXAMPLE CONFIGURATION     #\\n#                              #\\n################################\\n\\n# This block is not actually functional configuration,\\n# but serves to illustrate the available configuration\\n# options and document them in a way that is accessible\\n# to users that `kubectl edit` this config map.\\n#\\n# These sample configuration options may be copied out of\\n# this example block and unindented to be in the data block\\n# to actually change the configuration.\\n\\n# metrics.backend-destination field specifies the system metrics destination.\\n# It supports either prometheus (the default) or stackdriver.\\n# Note: Using Stackdriver will incur additional charges.\\nmetrics.backend-destination: prometheus\\n\\n# metrics.stackdriver-project-id field specifies the Stackdriver project ID. This\\n# field is optional. When running on GCE, application default credentials will be\\n# used and metrics will be sent to the cluster's project if this field is\\n# not provided.\\nmetrics.stackdriver-project-id: \\\"\\u003cyour stackdriver project id\\u003e\\\"\\n\\n# metrics.allow-stackdriver-custom-metrics indicates whether it is allowed\\n# to send metrics to Stackdriver using \\\"global\\\" resource type and custom\\n# metric type. Setting this flag to \\\"true\\\" could cause extra Stackdriver\\n# charge.  If metrics.backend-destination is not Stackdriver, this is\\n# ignored.\\nmetrics.allow-stackdriver-custom-metrics: \\\"false\\\"\\n\"},\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"labels\":{\"app.kubernetes.io/instance\":\"default\",\"app.kubernetes.io/part-of\":\"tekton-pipelines\"},\"name\":\"config-observability\",\"namespace\":\"tekton-pipelines\"}}\n"},"labels":{"app.kubernetes.io/instance":"default","app.kubernetes.io/part-of":"tekton-pipelines"}}}
to:
Resource: "/v1, Resource=configmaps", GroupVersionKind: "/v1, Kind=ConfigMap"
Name: "config-observability", Namespace: "tekton-pipelines"
for: "tekton-pipelines-release.yaml": Internal error occurred: failed calling webhook "config.webhook.pipeline.tekton.dev": Post https://tekton-pipelines-webhook.tekton-pipelines.svc:443/config-validation?timeout=10s: no endpoints available for service "tekton-pipelines-webhook"
